Harvard Mark2 是用继电器充当的（数字逻辑）基本原件（类似真空管，晶体管）

继电器

50HZ开关频率



第一只BUG，是从这个机器中找出来的 





三极管，真空管的前身，是一个二极管（热电子管），之后加入了第三个控制极，才形成了和继电器类似的效果



第一个晶体管

10KHZ的 开关频率



---

3



#### 数字电路，逻辑门，布尔代数



二进制。。   布尔代数。。把自动逻辑联系在了一起

《逻辑的数学分析》



用一个晶体管，稍加修改，就可以得到非门（发明这个的人6的飞起）

![1547909093276](C:\Users\cyy\AppData\Roaming\Typora\typora-user-images\1547909093276.png)



AND

需要2个晶体管

![1547909307265](C:\Users\cyy\AppData\Roaming\Typora\typora-user-images\1547909307265.png)

或门

![1547909773051](C:\Users\cyy\AppData\Roaming\Typora\typora-user-images\1547909773051.png)

也需要2个晶体管（并联起来，只要其中1个通电，整个输出就至少有1个电流源通电过来）



XOR门

直接用晶体管的话，脑子有点不够用。这需要一种能力，能够识别这种情况，然后将逻辑抽象打包（类似于从面向过程走向面向对象）升级，暂时尝试抛弃用晶体管考虑，直接用逻辑门符号考虑。

![1547911591989](C:\Users\cyy\AppData\Roaming\Typora\typora-user-images\1547911591989.png)



先尝试从第一种输入情况 I1 = 1，I2=0 开始考虑，尝试实现一部分真值表，看看能不能接近想要的效果。如果不行再修补。是否能化简，等实现基本功能后，再从逻辑门电路，转入更细微的晶体管为单位的电路，看看能不能做约简。

但是我做的这个不好，应该首先从最接近答案的，最相似的开始入手。

比如 先放一个 或门 

![1547911504811](C:\Users\cyy\AppData\Roaming\Typora\typora-user-images\1547911504811.png)

这种更好，少用一个非门





CPU的设计师，也很少直接用晶体管极的细粒度直接设计，他们大多数时候都是用门电路



---

4

#### 二进制



![1547913850805](C:\Users\cyy\AppData\Roaming\Typora\typora-user-images\1547913850805.png)

加法器



优化空间还有很多



---



计算机5大部件 ACMIO

ALU,CONTROLER,MEMORY,INPUT,OUTPUT





ALU

1个算数单元 + 1个逻辑单元



算数单元：

加减

半加器

![1547917631023](C:\Users\cyy\AppData\Roaming\Typora\typora-user-images\1547917631023.png)

全加器

![1547917622987](C:\Users\cyy\AppData\Roaming\Typora\typora-user-images\1547917622987.png)









加法器

低位的进位输出 ，连接高位的 进位输入

依次一直链式的连接



单现代计算机的加法器电路有些不一样（在一定程度上，可以让每一位都并行化，这有点像是做硬件逻辑电路上的，串行和并行的‘算法’优化）



---



内存



SRAM ， 寄存器

=

锁1 + 锁0 ，读写允许



---



CPU的主频率，根据晶振来驱动

CPU内有2个主要元件 ALU,和控制单元

指令的识别，也是根据逻辑电路来，根据指令寄存器中存储的指令代码，译码电路一般用很多个于门和非门，来确定指令是哪个，

然后根据指令的内容，驱动例如内存可写可读控制线上的信号

---

增加指令位(RISC)

可变指令长度（CISC)

---

09

高级CPU设计



**CACHE， 缓存**

缓存是用来加快，CPU想要从RAM中读取数据的情况

CPU从内存中加载数据的时候，一般会通过CACHE，直接相关所读取的RAM地址的相关部分，也就是一整块一整块的将RAM的数据COPY到CACHE中，常见场景如CPU想要累加100条在RAM中的数据，此时当CPU想取下一条数据的时候，如果CACHE中已经加载了所需要的数据，那么CACHE会直接将缓存的数据传递给CPU，这叫做**缓存命中**（否则叫做 缓存未命中）。CACHE的读写速度比起RAM来要快许多。所以CPU在需要读取和内存地址中顺序的数据时会大大提高处理速度（这也是最常见的情况）。



**脏读**

但是当CPU要向内存写数据时，也可以向CACHE中写数据，但是这会带来一个问题，就是CACHE中的数据被修改后，会和RAM中的不一致，所以每个CACHE中的字节，都会有一个状态位，叫做‘脏读’，当下一次CACHE和内存同步的时候，会把标记为‘脏读’的数据，用来覆盖RAM。比如下次CACHE读新数据的时候，先将脏读的数据写入RAM。然后在将要读取的新数据读取进来



**指令流水线**

将可以并行处理的部分进行了优化，比如当第一条流水线准备取指，解码，执行。

第二条流水线会在第一条流水线开始解码的时候，开始取指操作（很有可能是取内存地址的下一位置的指令），然后第三条。第四条。。。



这也会遇到类似数据脏读的问题，比如第二条指令的数据，会被第一条指令执行后进行修改，那么第二条指令的执行，得等到第一条指令执行完毕才能进行（CPU得分清楚指令之间的*数据依赖关系*）。

那么CPU会让第二条流水线停工。

为了优化停工的环节

其他CPU加快执行速度的方式还有例如，动态排序，来最小化停工时间。这叫**乱序执行**



类似JUMP的指令也会有这种问题，现代CPU会根据概率大小来猜测，JUMP是否会执行。这叫**推测执行**

如果CPU猜对了，那么后面的流水线已经塞满被已经处理好的指令，那么可以不浪费一分一秒的继续执行下去。

但是如果猜错了。后面流水线中的数据必须重置，并重新从对的内存地址开始挨个加载数据

为了能提高猜中的概率，现代CPU有**分支预测**，90%正确率。。。

**超标量流水线** （并行）一个指令周期，并行完成多个指令，这是在赌 上一条和下一条指令之间，没有依赖关系。

一般来说，CPU加速的方式是，尽可能的去并行化的处理能够并行化的任务。

到现在为止所谈的是一个**指令流**

另一种并行提速的方式是，多指令流（**多核心处理器**），多线程（多ALU，多流水线）

再往后就是**多CPU**



总的来说，优先级是 先串行（保证正确性），当不需要串行时，才做并行处理（加速）



---

算法



成为算法科学家的核心是，是使用已有算法，还是根据需求才需要自己写算法

（熟知已有算法，是写算法的基石）

---

数据结构

是为了方便 结构化的 被算法使用

常见的数据结构

数组

链表

队列

栈

树

堆

图

散列表

---

准确判定算法

是否有一种算法，可以根据输入的逻辑语句，准确的回答YES.NO的答案



lambada 算法，就是此问题的证明，证明了，这**不存在**

图灵机可以实现lambada算子相同的功能

图灵完备

停机问题，这本身就是 lambada所证明出来的问题。。不能

---

软件工程



---

光刻技术的 光的波长 和精度？ 有什么关系？ 为什么？



---

操作系统



内核恐慌

现在的好多商业软件，就像 MULTX 一样，有很多尝试从错误中恢复的代码，而UNIX的诞生，却希望让内核直接崩溃，直接抛出异常，而不是试图使恢复它。

为什么？

我们在做项目的时候，这样做的理由是，为了更好的给客户提供不错的用户体验，不会让他们在嗨的时候被某个可能出现的小问题，卡在那里，这在我看来，以及我之前所受到的他人的影响，是绝对正确的。。

但我猜。。这其中可能有一个隐含的人性上的问题。

一些人自己不会编程，（也许会。。）但他们自己说出的话中，让你去实现某功能，它自己都没有完整的在脑子里过一遍，把问题非常清楚的描述给实现人员。或者是试图隐藏某些事情（如违法的事情），这样就可以不被人所察觉，但当这些看似模糊的逻辑实现在运行的过程中，计算机可以忠诚的抛出异常，告诉你，某处有不合理的逻辑出现，这时可能你的领导，才会在心理恐慌，然后立刻思考一下，怎么把这事情圆过去。。。



当内核出现不可恢复的问题时

会调用叫做 panic （恐慌）

的函数，来输出状态信息

---

文件系统



元数据，描述数据的数据



文件系统使用 分块(BLOCK)给每个文件分配存储空间，块是一段数据大小一致的存储空间，有时一个文件在修改后，增加了长度，为了避免存储在类似数组一样过于紧凑的数据结构下，会发生将后续块平移的操作（时间），所以故意设计成具有固定大小，方便文件在小量增加数据时，不必频繁的平移块。（空间换时间）

描述这个文件夹内有哪些文件的  ’文件夹数据结构’中，记录了每条文件的信息，如文件所使用的块的编号，文件的名字，读写权限等。。

碎片整理（将属于一个大文件的多个块，通过重新排列，将他们以连续的顺序放在一起）

文件夹套文件夹的方式叫 **分层文件系统**



当你从一个文件夹中剪切一个文件到这个文件夹中的子文件夹中，速度会比，从C盘剪切到D盘快很多，就是因为，这个操作只需要把父文件夹中的这个文件记录信息，移动到子文件夹中，而不必重新读写文件所实际使用的块内的数据，因为块的编号并没有改变。而从C盘剪切到D盘，是因为这2个盘符之间是逻辑独立的，也就是C盘中的文件数据的块信息在剪切时，对D盘而言是不存在的，所以剪切时，需要将该文件所有的块内的数据拷贝到D盘中，所以文件越大速度越慢，这比起只移动文件的元数据的区区不过1k的信息而言要慢得多。

---

数据压缩



游程编码，字典编码（霍夫曼编码，树）

消除冗余

用紧凑的方法表达



有损压缩对人而言，其中一个最重要引入的概念，不是数据，是心理学。

JPEG 就是把图片拆分成小个的8x8像素的网格，然后在网格里根据情况压缩。

类似的，视频也可以压缩，视频是一连串的图片构成，所以在前一帧和后一帧之间，可以根据各个像素的变化率，采取类似的有损压缩方式，（因为画面有有些部分会出现长时间相同的图像）

这叫**时间冗余**





---

原来早期的

终端

其实是纸质打字机，但是可以联网

有类似远程终端的功能，可以互相聊天

屏幕是后面才加上的



命令行界面的祖先是，电传终端，他的祖先是电传打字机。。。



---

CRT

矢量扫描

让电子一直发射，并通过控制电子发射器出口处的电磁铁，改变磁场在X,Y方向上的强弱，控制电子落在屏幕上的位置，通过循环控制电磁铁位置，循环的让电子落在需要绘制图案的地方（连续）

光栅扫描

一行行的处理每个像素点，但是只在需要被点亮的像素点处，发射电子（离散，光栅化的）



第一块显卡（字符代码转换图形（光栅化的））

**字符生成器**



从某种意义上讲

当计算机的内存发展到一定程度时，

字符生成器会访问内存中特定的区域，这块区域叫 屏幕缓冲区（显存）

虽然可以显示任何字符，但是却无法精确的控制每个像素的显示方式，也就是说无法显示精确的图片



**矢量图形显示**

全部按划线的方式绘制，包括文字。

这有点类似 android 中 canvas的 Path 的绘制方式，只不过它只支持划线，和控制线条强度，

所以这类显存中存放的数据是点信息与画笔强度信息



光笔

通过crt的刷新率，光笔所指向的区域，汇报给计算机，计算机根据时间差，计算取笔所指向的位置（类似任天堂 FC 上的光枪，打野鸭的游戏）



1971年全美不过7万台电传打字和7万台终端

那时比尔已经学会了编程。并摸过了PDP-10，距离捞第一桶金卖DOS，只差4年

过好今天，拿到今天该拿的钱，和物资，很重要



---



因为政府对火箭导弹，登月计划的资金扶持

其中阿波罗登月计划的导航计算机系统，对硬件（集成电路）的要求很高

所以得到大笔资金的集成电路制造商，开始变得多起来。

 在冷战后，政府财政拨款减低

企业为了生存，将很多东西外包

硅谷众多公司纷纷倒闭，裁员，合并的时候，

INTEL决定把精力不放在内存继承电路，而是放在处理器



为什么？！

他是怎么在那个环境下做出了，在今天看来非常超前和正确的决定的？



它不知是因为无路可走而必须看好半导体的前景。还是已经因为深思熟虑看到了前景，决定进一步在半导体领域‘深造’



他为什么看好？



---

19岁的盖茨。。

为ALTAIR 编写 BASIC



那时候我们连计算机都没见过，它已经学会了为计算机创造语言解释器

可想它小时候所接触到的东西有多么重要及先进

心理资源和生理资源还有物理资源多么丰富

钱一定很多。。。

他们的家人，在那个年代到底意识到了什么，产生了那么大的差距。

那时候，我们到底在做什么，如此落后？

他们为什么可以早早意识到哪些不知道是什么，但可以让他们领先，且富有的东西。



优先接触，并进入有前景的新生事物中

如 为个人计算机爱好者提供个人计算机上的东西，可以让你很有成就感。且￥



前提是你要有能接触到，以硬科学为基础的新生领域

但这个的前提又是，你要了解硬科学

前提是，有资源去了解，如买书钱（而不是穷的吃了上顿没下顿的情况）

前提是，有兴趣

前提是，心理资源高

前提是，生理资源高

前提是，物理资源高



其中还有个俱乐部成员，乔布斯。。。各种资源绝对低不到哪里去

商业的一个重要特性是

直接向市场提供  开箱即用  的高级抽象实现（打包卖，立即可用）

APPLE2 就是个例子



计算机硬件的普及（IBM的PC）

也是源于硬件标准开源

就像今天的 linux 开源后，绝大部分服务器系统都使用它类似

历史具有一定相似性的



苹果从 APPLE2 之后就使用 close source。。

---

恩格尔巴特

演示之母

的作者

发明了鼠标，网络实时视频聊天。

二战期间居然是在菲律宾当雷达操作员

之后 1956年，回到学校，取的博士学位。

那时他35岁。。。又是政府，军队背景



光标的概念是他提出的

因此，为了实现这个，才创造了鼠标

而他也知道苏泽兰的‘几何画板’

看来笔才是人类最自然能联想到的定位装置。。

鼠标都是参考了这个而来

---

3D显示



3D投影 算法

负责把3D的图形，降维到2D上（3d点坐标-》2d点坐标）

线框渲染（把2d点之间连线，可产生一个封闭图形）

填充图形（扫描线渲染）

先找到一个2D封闭图形的最小Y和最大Y

然后在这个矩阵内，从上到下，每行扫描

扫到X1和X2之间有焦点的坐标时，就填充这个区间的像素

填充的速度叫 ‘填充速率‘



抗锯齿

光照

纹理化



显卡为什么需要那么多可以并行计算的核心，但是单个核心性能并不是很强

为了可以快速处理3D图形中的三角形。

可以为每个三角形分配一个处理核心



---

指数退避

其中一个应用的地方是

计算机网络中，当数据传输拥时（载体被占用，冲突）

所有计算机等待1s+小随机数s 的时间后，重试

如果还冲突

就所有计算机等待2s+小随机

如果还冲突

则 2^n s ...一直这样加下去

直到不出现冲突

现在的以太网，和WIFI，也正使用者这种算法。。。

感觉好原始。。为什么不能再冲突发生后，让一个主控计算机，安排，谁优先发数据，谁其次，然后谁（这有点像CPU的时间片分配给不同进程，CPU可以根据进程的运行情况，多给密集型计算任务分配大时间片，给IO密集型，分配多片但时间短的时间片。。。这可能会被坏人利用。就像财富的分配，给富人更多，让他多多益善，少的，就要拿走哪怕他的全部。。。重点是那个总调度者。一旦不可控的至高权力出现，走向变成集权怪兽的道路，只是时间问题）



通过在2个子网中加入路由器，可以将原先的一个 冲突域 ，变为2个

变得发生全网冲突的可能性降低，例如在一个子网中发生冲突，交换器（网桥），不会将这个冲突传输到另一个子网，所以另一个子网可以正常运作，但如果2个子网之间的通信造成了冲突，就会早造成全网冲突。

并且可以让2个子网之内的信息交换可以互不干扰的同时发生（并行！）

这种用法有点像 cpu想从内存中读写数据，在网线上，先输出MAC地址，在网络中监听数据的计算机都看看自己MAC地址，检查自己是不是后续信息的接受者，若不是，类似于内存的选址存储单元的阶段未被选中的情况（只不过网络中是串行传递虚拟地址MAC信息的，内存是并行的），当某个机器被选中后，后续的网络数据则当做数据总线或控制总线上的数据



报文交换

路由



